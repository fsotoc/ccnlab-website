---
title: Research
nav:
  order: 1
  tooltip: Research
---

# {% include icon.html icon="fa-solid fa-microscope" %}Research

{%
  include button.html
  text="Philosophy"
  link="research/#our-philosophy"
%}

{%
  include button.html
  text="Research"
  link="research/#our-research"
%}


## Our Philosophy

### Computational: A model-based research approach
We believe that scientific progress is facilitated when we define our questions and hypotheses precisely, through the use of formal mathematical models. Are different aspects of a face (for example, identity and expression) represented independently? Are face parts represented holistically? It depends on what one means by "independently" and "holistically." Formal theories from psychology (e.g., [GRT]()) and neuroscience can provide precise definitions for such ambiguous concepts, and show us the way to experimentally measure them in both [behavioral]() and [neuroimaging]() experiments. What are the mechanisms by which depression influences perception of face expressions? What mechanisms underlie the deficit to recognize faces from a different race? We can use models (e.g., [perceptual observer models]() and [encoding models]()) to formalize multiple hypotheses and decide between them. For us, the use of computational models is not a gimmick. We see it as necessary to move the field forward.

### Cognitive: A focus on complex adaptive behavior
Our ultimate goal is to understand complex behavior that helps people adapt to their environment. We believe that this complexity arises from the [interaction of multiple, simpler mechanisms of cognitive computation](). For example, simple mechanisms that modify face representations (such as gain) can help explaining the [influence of category learning on face perception](), and the [influence of depression in expression perception](). Simple mechanisms of learning and representation can in part explain [how we learn to group objects into categories]().

### Neuroscience: Brain computation matters
The same observed behavior can be explained through multiple possible cognitive mechanisms (the [identifiability problem]()). How can we decide which one of them is closer to the truth? We believe that when alternative cognitive mechanisms are implemented using principles of neural computation, it becomes easier to tell them apart from both what we already know about the brain (are the mechanisms plausible?) and by collecting new data (do the mechanisms predict well both behavioral and neural data?)

### Face perception: The ideal testbed
In our daily lives, we must constantly process information from faces because of their importance for social interaction. The full range of complexity of our cognitive skills is revealed in face processing, from simply recognizing a friend to trying to figure out what they are thinking. On the other hand, faces are relatively simple objects and their properties been widely studied in medicine, anthropology, and computer graphics. This makes it easy to rigorously manipulate faces in research, through [3d modeling](). Face research is both rigorous and impactful, which is why we focus on it.

## Our Research

### How do different encoding strategies promote adaptive behavior?
- Two objects or features (e.g., face expression and identity) can be encoded independently or cohesively. [Cognitive theories](soto-bayesian) suggest that whether the brain uses either form of encoding depends on learned environmental statistics. Once such environmental structure is learned, it can greatly facilitate new learning and generalization.
- For example, learning a separate representation for a group of faces greatly [facilitates fast learning of new rules](Soto-Ashby).
- Learning that two events are independent causes of an effect leads to [summing]() their influence when they happen together, which is optimal, but there are conditions under which such [optimality can break down](Perez).
- How two features are encoded can thus give us clues about how they are used for adaptive behavior. Face features like identity and expression are thought to be independent in theories of vision, because that would facilitate identifying one while ignoring the other. On the other hand, they are thought to be interdependent in affective science, because that would facilitate their recongition in ambiguous social situations. We have found that they are [encoded in an integrated manner](Soto-Emily-Sanaz) according to multiple model-based measures. Similarly, [expectations of what expressive motion looks natural depends on the shape of a face](raphael). It seems like the complexity of social situations, and not a drive toward simple identification, that drives how face features are encoded.
- More generally, we believe that [encoding is flexible]() and depends on learning and cognitive control.

### How does learning influence face encoding?
- [categorization training influences how face identities are represented](Soto-ashby-many). Later research revealed that a simple [gain mechanism]() could explain these results.
- We are currently applying our insights to understand what conditions produce the so-called other-race effects in face perception. Our hypotheses are that different learning conditions produce different aspects of the other race effects, and simple mechanisms such as gain can account for the results.
- We are also interested in how making two features predict an outcome only when they happen together (non-linear discrimination tasks) may influence their encoding. Do previously independent features become more integrated and at what stage of processing? Is it possible to train people to encode memories that depend on a particular context? We are currently studying these questions.

### How do changes in affect influence face encoding?
- Depression is accopanied by deficits in perception of face expressoin. We have shown that a [reduction in gain]() for positive expressions may underlie this effect, and that this depends on a [reduction in signal-to-noise ratio]() rather than a change in how face information is used.
- We are interested in how learning the affective value of an object might influence its encoding. Are faces encoded differently if they are associated with negative or positive events?

### How does cognition influence face encoding?
- Whether perception depends on high-level cognition such as awareness or meta-cognitive states is a widely studied topic without a clear answer. We have used model-based approach to understand this better. In general we find that the accuracy of our [perception and memory do depend on awareness and metacognition](Pournaghdali).
- We are currenty interested in how more specific mechanisms of cognitive control may influence perceptual and memory encoding. For example, how does [error monitoring influence memory for faces](kia)? How does it influence perceptual encoding of face identities and expressions?